mean(betas[ 1:12])           # Want-items
mean(betas[13:24])           # Do-items
plotPImap(res_rm_1, cex.gen = .55)
plotPImap(res_rm_1, cex.gen = .55, sorted = TRUE)
round(sum(betas), 10)
tmp1 <- RM(dat_1, sum0 = FALSE)
round(coef(tmp1), 2)
rm_1 <- RM(responses_matrix)
library("eRm")
source("convert_to_binary.R")
setwd("~/")
library("eRm")
source("convert_to_binary.R")
rm_1 <- RM(responses_matrix)
setwd("~/Documents/Ladder Logic (Survey)")
library("eRm")
source("convert_to_binary.R")
setwd("~/Documents/Ladder Logic (Survey)/code")
library("eRm")
source("convert_to_binary.R")
rm_1 <- RM(responses_matrix)
library("eRm")
source("convert_to_binary.R")
rm_1 <- RM(responses_matrix)
1
1
1
rm_1 <- RM(responses_matrix)
confint(rm_1, "beta")
coef(rm_1)
plot(person.parameter(rm_1))
person.parameter(rm_1)
betas <- -coef(rm_1)
round(sort(betas), 2)
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
View(survey)
View(responses_matrix)
rm_1 <- RM(responses_matrix)
confint(rm_1, "beta")
coef(rm_1)
confint(rm_1, "beta")
coef(rm_1)
coef(rm_1)
betas <- -coef(rm_1)
round(sort(betas), 2)
coef(rm_1)
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
abline(h = .5, col = "black")
coef(rm_1)
betas <- -coef(rm_1)
round(sort(betas), 2)
abline(v = -2.05, col = "black")
abline(h = .2, col = "black")
abline(v = 1.40, col = "black")
plotICC(rm_1, item.subset = 1:10, ask = F, empICC = list("raw"),empCI = list(lty = "solid"))
abline(h = .5, col = "black")
abline(v = -2.05, col = "black")
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
abline(h = .5, col = "black")
abline(v = -2.05, col = "black")
abline(v = 1.40, col = "black")
plotPImap(rm_1, cex.gen = .8, sorted = TRUE, irug = TRUE)
setwd("~/Documents/Reddit (Survey)")
library(readr)
object_analysis <- read_csv("../data/object-analysis.csv")
object_analysis <- read_csv("data/object-analysis.csv")
View(object_analysis)
clusters <- kmeans(object_analysis[,3:91], 5)
object_analysis$cluster <- as.factor(clusters$cluster)
View(clusters)
View(object_analysis)
str(clusters)
distance <- get_dist(df)
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
distance <- get_dist(df)
distance <- get_dist(object_analysis)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
k2 <- kmeans(object_analysis, centers = 2, nstart = 25)
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
distance <- get_dist(object_analysis)
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
object_analysis <- na.omit(object_analysis)
distance <- get_dist(object_analysis)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
clusters <- kmeans(object_analysis[,3:30], 5)
object_analysis <- na.omit(object_analysis)
distance <- get_dist(object_analysis)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
object_analysis <- object_analysis[,3:10]
View(object_analysis)
object_analysis <- na.omit(object_analysis)
distance <- get_dist(object_analysis)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
object_analysis <- object_analysis[,3:5]
object_analysis <- na.omit(object_analysis)
distance <- get_dist(object_analysis)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
object_analysis <- na.omit(object_analysis)
distance <- get_dist(object_analysis)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
k2 <- kmeans(object_analysis, centers = 2, nstart = 25)
k2 <- kmeans(object_analysi)
kmean <- kmeans(object_analysis)
kmean <- kmeans(object_analysis, centers = 10)
kmean <- kmeans(object_analysis, centers = 1)
kmean <- kmeans(object_analysis, centers = 1)
kmean <- kmeans(object_analysis, 5)
k2 <- kmeans(object_analysis[,3:30], 5)
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
object_analysis <- na.omit(object_analysis)
distance <- get_dist(object_analysis)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
k2 <- kmeans(object_analysis[,3:30], 5)
fviz_cluster(k2, data = object_analysis)
k2 <- kmeans(object_analysis[,3:30], 5)
str(k2)
fviz_cluster(k2, data = object_analysis)
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
k.means.fit <- kmeans(object_analysis, 3) # k = 3
# 3 - 91
object_analysis <- read_csv("data/object-analysis.csv")
k.means.fit <- kmeans(object_analysis, 3) # k = 3
View(object_analysis)
values <- csv_file[,3:91]
library(readr)
# 3 - 91
csv_file <- read_csv("data/object-analysis.csv")
values <- csv_file[,3:91]
k.means.fit <- kmeans(object_analysis, 3) # k = 3
View(values)
library(readr)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
# 3 - 91
values <- read_csv("data/object-analysis.csv")
k.means.fit <- kmeans(values, 3) # k = 3
attributes(k.means.fit)
k.means.fit$centers
k.means.fit$cluster
k.means.fit$size
wssplot <- function(data, nc=15, seed=1234){
wss <- (nrow(data)-1)*sum(apply(data,2,var))
for (i in 2:nc){
set.seed(seed)
wss[i] <- sum(kmeans(data, centers=i)$withinss)}
plot(1:nc, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")}
wssplot(values, nc=6)
k.means.fit <- kmeans(values, 5) # k = 3
k.means.fit$size
wssplot <- function(data, nc=15, seed=1234){
wss <- (nrow(data)-1)*sum(apply(data,2,var))
for (i in 2:nc){
set.seed(seed)
wss[i] <- sum(kmeans(data, centers=i)$withinss)}
plot(1:nc, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")}
wssplot(values, nc=6)
library(cluster)
clusplot(values, k.means.fit$cluster, main='2D representation of the Cluster solution',
color=TRUE, shade=TRUE,
labels=2, lines=0)
k.means.fit <- kmeans(values, 5) # k = 3
clusplot(values, k.means.fit$cluster, main='2D representation of the Cluster solution',
color=TRUE, shade=TRUE,
labels=2, lines=0)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
k.means.fit <- clara(values, 5) # k = 3
k.means.fit$size
k.means.fit
library(cluster)
clusplot(values, k.means.fit$cluster, main='2D representation of the Cluster solution',
color=TRUE, shade=TRUE,
labels=2, lines=0)
clara(values, 5, metric = "euclidean", stand = FALSE,
samples = 50, pamLike = FALSE)
install.packages(c("cluster", "factoextra"))
install.packages(c("cluster", "factoextra"))
library(cluster)
library(factoextra)
clx3 <- clara(values, 5, metric = "euclidean", stand = FALSE,
samples = 50, pamLike = FALSE)
library(cluster)
library(factoextra)
plot(clx3, ask = TRUE)
plot(clx3, ask = TRUE)
library(FactoMineR)
cah.test <- HCPC(x, graph=FALSE, nb.clust=-1)
cah.test <- HCPC(values, graph=FALSE, nb.clust=-1)
cah.test <- HCPC(values, graph=FALSE, nb.clust=-1)
cl <- kmeans(values, 5, iter.max=20)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
library(readr)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
library(FactoMineR)
cah.test <- HCPC(values, graph=FALSE, nb.clust=-1)
library(readr)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
View(values)
library(FactoMineR)
cah.test <- HCPC(values, graph=FALSE, nb.clust=-1)
View(cah.test)
cl <- kmeans(values, 5, iter.max=20)
plot.HCPC(cah, choice="tree")
cah <- HCPC(cl$centers, graph=FALSE, nb.clust=-1)
cl <- kmeans(values, 5, iter.max=20)
cah <- HCPC(cl$centers, graph=FALSE, nb.clust=-1)
plot.HCPC(cah, choice="tree")
View(values)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
kmeans.big.matrix(values, centers, iter.max = 10, nstart = 1,
algorithm = "MacQueen", tol = 1e-8,
parallel = NA, nwssleigh = NULL)
library(bigmatrix)
library(bigmemory)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
kmeans.big.matrix(values, centers, iter.max = 10, nstart = 1,
algorithm = "MacQueen", tol = 1e-8,
parallel = NA, nwssleigh = NULL)
library(nws)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
kmeans.big.matrix(values, centers, iter.max = 10, nstart = 1,
algorithm = "MacQueen", tol = 1e-8,
parallel = NA, nwssleigh = NULL)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
bigkmeans(x, centers, iter.max = 10, nstart = 1, dist = "euclid")
library(biganalytics)
# 3 - 91
values <- read_csv("data/object-analysis.csv")
bigkmeans(x, centers, iter.max = 10, nstart = 1, dist = "euclid")
# 3 - 91
values <- read_csv("data/object-analysis.csv")
bigkmeans(values, iter.max = 10, nstart = 1, dist = "euclid")
bigkmeans(values, centers = 10, iter.max = 10, nstart = 1, dist = "euclid")
bigkmeans(as.matrix(values), centers = 10, iter.max = 10, nstart = 1, dist = "euclid")
ca <- bigkmeans(as.matrix(values), centers = 10, iter.max = 10, nstart = 1, dist = "euclid")
fviz_cluster(ca, data = values)
ca <- bigkmeans(as.matrix(values), centers = 100, iter.max = 10, nstart = 1, dist = "euclid")
fviz_cluster(ca, data = values)
ca <- bigkmeans(as.matrix(values), centers = 100, iter.max = 10, nstart = 1, dist = "euclid")
fviz_cluster(ca, data = values)
ca <- bigkmeans(as.matrix(values), centers = 10, iter.max = 10, nstart = 1, dist = "euclid")
fviz_cluster(ca, data = values)
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two dendrograms
# 3 - 91
df <- read_csv("data/object-analysis.csv")
df <- na.omit(df)
df <- scale(df)
d <- dist(df, method = "euclidean")
hc1 <- hclust(d, method = "complete" )
plot(hc1, cex = 0.6, hang = -1)
plot(hc1, cex = 0.1, hang = -1)
plot(hc1, cex = 0.2, hang = -1)
# 3 - 91
df <- read_csv("data/object-analysis.csv")
df <- na.omit(df)
d <- dist(df, method = "euclidean")
hc1 <- hclust(d, method = "complete" )
plot(hc1, cex = 0.2, hang = -1)
hc2 <- agnes(df, method = "complete")
# methods to assess
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
# function to compute coefficient
ac <- function(x) {
agnes(df, method = x)$ac
}
map_dbl(m, ac)
##   average    single  complete      ward
## 0.7379371 0.6276128 0.8531583 0.9346210
hc3 <- agnes(df, method = "ward")
pltree(hc3, cex = 0.6, hang = -1, main = "Dendrogram of agnes")
View(df)
# 3 - 91
df <- read_csv("data/object-analysis.csv")
df <- data.frame(t(df[-1]))
df <- na.omit(df)
d <- dist(df, method = "euclidean")
hc1 <- hclust(d, method = "complete" )
plot(hc1, cex = 0.2, hang = -1)
hc2 <- agnes(df, method = "complete")
# 3 - 91
df <- read_csv("data/object-analysis.csv")
df <- data.frame(t(df[-1]))
df <- na.omit(df)
d <- dist(df, method = "euclidean")
hc1 <- hclust(d, method = "complete" )
plot(hc1, cex = 0.7, hang = -1)
# 3 - 91
df <- read_csv("data/object-analysis.csv")
df <- data.frame(t(df[-1]))
df <- na.omit(df)
d <- dist(df, method = "euclidean")
hc1 <- hclust(d, method = "complete" )
plot(hc1, cex = 0.6, hang = -1)
plot(hc1, cex = 0.6, hang = -1, srt=60)
hc2 <- agnes(df, method = "complete")
plot(hc1, cex = 0.6, hang = -1, srt=60)
plot(hc1, cex = 0.6, hang = -1, las=1)
plot(hc1, cex = 0.6, hang = -1, las=2)
p <- plot(hc1, cex = 0.6, hang = -1, las=2, xaxt="n")
labs <- paste(names(table(hc1)), "cylinders")
p <- plot(hc1, cex = 0.6, hang = -1, las=2)
hc1 <- hclust(d, method = "complete" )
p <- plot(hc1, cex = 0.4, hang = -1, las=2)
p <- plot(hc1, cex = 0.5, hang = -1, las=2)
hc2 <- agnes(df, method = "complete")
# methods to assess
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
# function to compute coefficient
ac <- function(x) {
agnes(df, method = x)$ac
}
map_dbl(m, ac)
##   average    single  complete      ward
## 0.7379371 0.6276128 0.8531583 0.9346210
hc3 <- agnes(df, method = "ward")
pltree(hc3, cex = 0.6, hang = -1, main = "Dendrogram of agnes")
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two dendrograms
# 3 - 91
df <- read_csv("data/object-analysis.csv")
df <- data.frame(t(df[-1]))
df <- na.omit(df)
d <- dist(df, method = "euclidean")
hc1 <- hclust(d, method = "complete" )
p <- plot(hc1, cex = 0.5, hang = -1, las=2)
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two dendrograms
# 3 - 91
df <- read_csv("data/object-analysis.csv")
df <- data.frame(t(df[-1]))
df <- na.omit(df)
d <- dist(df, method = "euclidean")
hc1 <- hclust(d, method = "complete" )
p <- plot(hc1, cex = 0.5, hang = -1, las=2)
p <- plot(hc1, cex = 0.75, hang = -1, las=2)
p <- plot(hc1, cex = 0.65, hang = -1, las=2)
p <- plot(hc1, cex = 0.6, hang = -1, las=2)
p <- plot(hc1, cex = 0.6, hang = -1, las=2, horiz=T)
p <- plot(hc1, cex = 0.6, hang = -1, las=2, horiz=TRUE)
warnings()
library(dendextend)
dend_labels <- labels(dend)
labels(dend) <- ""
dend_labels <- labels(hc1)
labels(hc1) <- ""
p <- plot(hc1, cex = 0.6, hang = -1, las=2)
dend_labels <- labels(p)
labels(p) <- ""
# 3 - 91
df <- read_csv("data/object-analysis.csv")
df <- data.frame(t(df[-1]))
df <- na.omit(df)
d <- dist(df, method = "euclidean")
hc1 <- hclust(d, method = "complete" )
library(dendextend)
p <- plot(hc1, cex = 0.6, hang = -1, las=2)
dend_labels <- labels(p)
labels(p) <- ""
dend <- as.dendogram(hc1.D)
dend <- as.dendrogram(hc1.D)
dend <- as.dendrogram(hc1)
dend_labels <- labels(dend)
labels(dend) <- ""
p <- plot(dend, cex = 0.6, hang = -1, las=2)
text(x = 1:length(dend_labels), labels = dend_labels, srt = 45, adj = c(1,1), xpd = T)
hc1 <- hclust(d, method = "complete" )
p <- plot(hc1, cex = 0.6, hang = -1, las=2)
hc1 <- hclust(d, method = "complete" )
p <- plot(hc1, cex = 0.6, hang = -1, las=2)
plot(hc1, type = "triangle", ylab = "Height")
plot(hc1, type = "triangle", ylab = "Height")
warnings()
hc1 <- as.dendrogram(hclust(d, method = "complete" ))
p <- plot(hc1, cex = 0.6, hang = -1, las=2)
hc1 <- hclust(d, method = "complete" )
p <- plot(hc1, cex = 0.6, hang = -1, las=2)
p <- plot(hc1, cex = 0.6, hang = -1, las=2, horiz = TRUE)
p <- plot.dendrogram(hc1, cex = 0.6, hang = -1, las=2, horiz = TRUE)
p <- plot.dendrogram(hc1, cex = 0.6, hang = -1, las=2)
hc1 <- hclust(d, method = "complete" )
p <- plot(as.dendrogram(hc1), horiz = TRUE)
p <- plot(as.dendrogram(hc1), cex = 0.6, hang = -1, horiz = TRUE)
hc1 <- hclust(d, method = "complete" )
hc1 <- hclust(d, method = "complete" )
p <- plot(as.dendrogram(hc1), cex = 0.6, horiz = TRUE)
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
?plot.dendrogram
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
p
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
p
par(cex = 0.2)
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.5)
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.6)
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.55)
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.55, mar=c(5, 8, 4, 1))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.55, mar=c(1, 1, 1, 5))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.55, mar=c(1, 1, 1, 8))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.55, mar=c(1, 1, 1, 15))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.55, mar=c(1, 1, 1, 12))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.55, mar=c(1, 1, 1, 11))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.55, mar=c(2, 2, 2, 11))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.5, mar=c(2, 2, 2, 11))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE, edgePar = list(col = 2:3, lwd = 2:1))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
par(cex = 0.5, mar=c(2, 2, 2, 12))
p <- plot(as.dendrogram(hc1), cex = 0.2, horiz = TRUE)
setwd("~/Documents/Ladder Logic (Survey)/code")
source("convert_to_binary.R")
rm_1 <- RM(responses_matrix)
betas <- -coef(rm_1)
round(sort(betas), 2)
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
rm_1 <- RM(responses_matrix)
library("eRm")
source("convert_to_binary.R")
rm_1 <- RM(responses_matrix)
betas <- -coef(rm_1)
round(sort(betas), 2)
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
plotICC(rm_1, item.subset = 1:10, ask = F, empICC = list("raw"),empCI = list(lty = "solid"))
abline(h = .5, col = "black")
abline(v = -2.05, col = "black")
abline(v = 1.40, col = "black")
abline(h = .2, col = "black")
plotPImap(rm_1, cex.gen = .8, sorted = TRUE, irug = TRUE)
rm_1 <- RM(responses_matrix)
betas <- -coef(rm_1)
round(sort(betas), 2)
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
abline(h = .5, col = "black")
library("eRm")
source("convert_to_binary.R")
rm_1 <- RM(responses_matrix)
betas <- -coef(rm_1)
round(sort(betas), 2)
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
abline(h = .5, col = "black")
abline(v = -2.05, col = "black")
abline(v = 1.40, col = "black")
abline(h = .2, col = "black")
plotPImap(rm_1, cex.gen = .8, sorted = TRUE, irug = TRUE)
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
View(responses_matrix)
library("eRm")
source("convert_to_binary.R")
rm_1 <- RM(responses_matrix)
betas <- -coef(rm_1)
round(sort(betas), 2)
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
abline(h = .5, col = "black")
abline(v = -2.05, col = "black")
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
abline(v = 1.40, col = "black")
abline(h = .2, col = "black")
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
abline(h = .5, col = "black")
abline(v = 1.40, col = "black")
plotPImap(rm_1, cex.gen = .8, sorted = TRUE, irug = TRUE)
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
abline(v = .5, col = "black")
abline(v = 0, col = "black")
plotjointICC(rm_1, item.subset = 1:10, cex = .6, lwd=1.5 )
abline(v = 0, col = "black")
View(rm_1)
plotPImap(rm_1, cex.gen = .8, sorted = TRUE, irug = TRUE)
